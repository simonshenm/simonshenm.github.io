<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Pytorch实践：SHOT, 计算机科学在读 | 爱生活 | 爱思考">
    <meta name="description" content="  Pytorch实践：SHOT
实验机器：Google Colab,MistGPU 2080Ti
github原地址：https://github.com/tim-learn/SHOT
我的github地址（建议看这个，因为我踩过坑了）：">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>Pytorch实践：SHOT | 沿溪行</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    
    <script src="/libs/jquery/jquery.min.js"></script>
    
    
    <link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" rel="stylesheet" type="text/css">


<meta name="generator" content="Hexo 4.2.0"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/favicon.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">沿溪行</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/favicon.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">沿溪行</div>
        <div class="logo-desc">
            
            一个人知道自己为什么而活，就能忍受任何一种生活
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/simonshenm" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/simonshenm" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://s3.ax1x.com/2020/11/18/De7LJf.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Pytorch实践：SHOT</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">
    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Pytorch/">
                                <span class="chip bg-color">Pytorch</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Pytorch/" class="post-category">
                                Pytorch
                            </a>
                        
                            <a href="/categories/Pytorch/SHOT/" class="post-category">
                                SHOT
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2020-11-15
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    4.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    28 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>

        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="centering-pytorch实践shot"><a class="markdownIt-Anchor" href="#centering-pytorch实践shot"></a> <centering> Pytorch实践：SHOT</h2>
<p>实验机器：Google Colab,MistGPU 2080Ti</p>
<p>github原地址：<a href="https://github.com/tim-learn/SHOT" target="_blank" rel="noopener">https://github.com/tim-learn/SHOT</a></p>
<p>我的github地址（建议看这个，因为我踩过坑了）：<a href="https://github.com/simonshenm/SHOT_ICML2020" target="_blank" rel="noopener">https://github.com/simonshenm/SHOT_ICML2020</a></p>
<h3 id="实验1unsupervised-closed-set-domain-adaptation-uda-on-the-digits-dataset"><a class="markdownIt-Anchor" href="#实验1unsupervised-closed-set-domain-adaptation-uda-on-the-digits-dataset"></a> 实验1：Unsupervised Closed-set Domain Adaptation (UDA) on the Digits dataset</h3>
<p><strong>实验代码</strong></p>
<ul>
<li>代码1：<a href="http://network.py" target="_blank" rel="noopener">network.py</a></li>
</ul>
<pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torchvision
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> models
<span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> math
<span class="hljs-keyword">import</span> torch.nn.utils.weight_norm <span class="hljs-keyword">as</span> weightNorm
<span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> OrderedDict

<span class="hljs-string">"""
初始化权重:
目的是防止在深度神经网络的正向（前向）传播过程中层激活函数的输出损失梯度出现爆炸或消失。
如果发生任何一种情况，损失梯度太大或太小，就无法有效地向后传播，并且即便可以向后传播，网络也需要花更长时间来达到收敛。
https://zhuanlan.zhihu.com/p/62850258
"""</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">init_weights</span><span class="hljs-params">(m)</span>:</span>
    classname = m.__class__.__name__
    <span class="hljs-keyword">if</span> classname.find(<span class="hljs-string">'Conv2d'</span>) != <span class="hljs-number">-1</span> <span class="hljs-keyword">or</span> classname.find(<span class="hljs-string">'ConvTranspose2d'</span>) != <span class="hljs-number">-1</span>:
        nn.init.kaiming_uniform_(m.weight)
        nn.init.zeros_(m.bias)
    <span class="hljs-keyword">if</span> classname.find(<span class="hljs-string">'BatchNorm'</span>) != <span class="hljs-number">-1</span>:
        nn.init.normal_(m.weight, <span class="hljs-number">1.0</span>, <span class="hljs-number">0.02</span>)
        nn.init.zeros_(m.bias)
    <span class="hljs-keyword">if</span> classname.find(<span class="hljs-string">'Linear'</span>) != <span class="hljs-number">-1</span>:
        nn.init.xavier_normal_(m.weight)
        nn.init.zeros_(m.bias)

        
        
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">feat_bottleneck</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, feature_dim, bottleneck_dim = <span class="hljs-number">256</span>, type = <span class="hljs-string">"ori"</span>)</span>:</span>
        super(self, feat_bottleneck).__init__()
        self.bn = nn.BatchNorm1d(bottleneck_dim, affine = <span class="hljs-literal">True</span>)
        self.dropout = nn.Dropout(p = <span class="hljs-number">0.5</span>)
        self.bottleneck = nn.Linear(feature_dim, bottleneck_dim)
        self.bottleneck.apply(init_weights)
        self.type = type
        
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        x = self.bottleneck(x)
        <span class="hljs-keyword">if</span> self.type == <span class="hljs-string">"bn"</span>:
            x = self.bn(x)
            x = self.dropout(x)
        <span class="hljs-keyword">return</span> x

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">feat_classifier</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, class_num, bottleneck_dim = <span class="hljs-number">256</span>, type = <span class="hljs-string">"linear"</span>)</span>:</span>
        super(self, feat_classifier).__init__()
        <span class="hljs-keyword">if</span> type == <span class="hljs-string">"linear"</span>:
            self.fc = nn.Linear(bottleneck_dim, class_num)
        <span class="hljs-keyword">else</span>:
            self.fc = weightNorm(nn.Linear(bottleneck_dim, class_num), name = <span class="hljs-string">"weight"</span>)
        self.fc.apply(init_weights)
    
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        x = self.fc(x)
        <span class="hljs-keyword">return</span> x
    
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">DTNBase</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
        super(self, DTNBase).__init__()
        self.conv_params = nn.sequential(
            nn.Conv2d(in_channels = <span class="hljs-number">3</span>, out_channels = <span class="hljs-number">64</span>, kernel_size = <span class="hljs-number">5</span>, stride = <span class="hljs-number">2</span>, padding = <span class="hljs-number">2</span>)
            nn.BatchNorm2d(<span class="hljs-number">64</span>),
            nn.Dropout(p = <span class="hljs-number">0.1</span>),
            nn.ReLU(inplace = <span class="hljs-literal">True</span>),
            
            nn.Conv2d(in_channels = <span class="hljs-number">64</span>, out_channels = <span class="hljs-number">128</span>, kernel_size = <span class="hljs-number">5</span>, stride = <span class="hljs-number">2</span>, padding = <span class="hljs-number">2</span>)
            nn.BatchNorm2d(<span class="hljs-number">128</span>),
            nn.Dropout(p = <span class="hljs-number">0.3</span>),
            nn.ReLU(inplace = <span class="hljs-literal">True</span>),
            
            nn.Conv2d(in_channels = <span class="hljs-number">128</span>, out_channels = <span class="hljs-number">256</span>, kernel_size = <span class="hljs-number">5</span>, stride = <span class="hljs-number">2</span>, padding = <span class="hljs-number">2</span>),
            nn.BatchNorm2d(<span class="hljs-number">256</span>),
            nn.Dropout(p = <span class="hljs-number">0.5</span>),
            nn.ReLU(inplace = <span class="hljs-literal">True</span>)
        )
        self.in_features = <span class="hljs-number">256</span>*<span class="hljs-number">4</span>*<span class="hljs-number">4</span>
        
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        x = self.conv_params(x)
        x = x.view(x.size(<span class="hljs-number">0</span>), <span class="hljs-number">-1</span>)
        <span class="hljs-keyword">return</span> x
    
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LeNetBase</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
        super(self, LeNetBase).__init__()
        self.conv_params = nn.sequential(
            nn.Conv2d(in_channels = <span class="hljs-number">1</span>, out_channels = <span class="hljs-number">20</span>, kernel_size = <span class="hljs-number">5</span>),
            nn.MaxPool2d(<span class="hljs-number">2</span>),
            nn.ReLU(inplace = <span class="hljs-literal">True</span>),
            nn.Conv2d(in_channels = <span class="hljs-number">20</span>, out_channels = <span class="hljs-number">50</span>, kernel_size =<span class="hljs-number">5</span>),
            nn.Dropout2d(p = <span class="hljs-number">0.5</span>),
            nn.MaxPool2d(<span class="hljs-number">2</span>),
            nn.ReLU(inplace = <span class="hljs-literal">True</span>)
        )
        self.in_features = <span class="hljs-number">50</span>*<span class="hljs-number">4</span>*<span class="hljs-number">4</span>
        
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        x = self.conv_params(x)
        x = x.view(x.size(<span class="hljs-number">0</span>), <span class="hljs-number">-1</span>)
        <span class="hljs-keyword">return</span> x

</code></pre>
<ul>
<li>代码2：<a href="http://loss.py" target="_blank" rel="noopener">loss.py</a></li>
</ul>
<pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> torch 
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable
<span class="hljs-keyword">import</span> math
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F
<span class="hljs-keyword">import</span> pdb

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">Entropy</span><span class="hljs-params">(input_)</span>:</span>
    bs = input_.size(<span class="hljs-number">0</span>)
    entropy = -input_*torch.log(input_ + <span class="hljs-number">1e-5</span>)
    entropy = torch.sum(entropy, dim = <span class="hljs-number">1</span>)
    <span class="hljs-keyword">return</span> entropy

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CrossEntropyLabelSmooth</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, num_classes, epsilon = <span class="hljs-number">0.1</span>, use_gpu = True, size_average = True)</span>:</span>
        super(self, CrossEntropyLabelSmooth).__init__()
        self.num_classes = num_classes
        self.epsilon = epsilon
        self.use_gpu = use_gpu
        self.size_average = size_average
        self.logsoftmax = nn.LogSoftmax(dim = <span class="hljs-number">1</span>)
        
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, inputs, targets)</span>:</span>
        log_probs = self.logsoftmax(inputs)
        targets = torch.zeros(log_probs.size()).scatter(<span class="hljs-number">1</span>, targets.unsqueeze(<span class="hljs-number">1</span>).cpu(),<span class="hljs-number">1</span>)
        <span class="hljs-keyword">if</span> self.use_gpu:
            targets = targets.cuda()
            targets = (<span class="hljs-number">1</span> - self.epsilon)*targets + self.epsilon / self.num_classes
        <span class="hljs-keyword">if</span> self.size_average:
            loss = (-targets * log_probs).mean(<span class="hljs-number">0</span>).sum()
        <span class="hljs-keyword">else</span>:
            loss = (-targets * log_probs).sum(<span class="hljs-number">1</span>)
        <span class="hljs-keyword">return</span> loss
</code></pre>
<ul>
<li>代码3：uda_digit.py</li>
</ul>
<pre class="highlight"><code class="python"><span class="hljs-keyword">import</span> argparse
<span class="hljs-keyword">import</span> os,sys
<span class="hljs-keyword">import</span> os.path <span class="hljs-keyword">as</span> osp
<span class="hljs-keyword">import</span> torchvision
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim
<span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms
<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-keyword">import</span> random,pdb,math,copy
<span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm
<span class="hljs-keyword">from</span> scipy.spatial.distance <span class="hljs-keyword">import</span> cdist
<span class="hljs-keyword">import</span> pickle
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> data_load <span class="hljs-keyword">import</span> mnist,svhn,usps
<span class="hljs-keyword">import</span> network,loss

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">op_copy</span><span class="hljs-params">(optimizer)</span>:</span>
    <span class="hljs-string">"""
    optimizer.param_groups[0]：长度为6的字典，包括[‘amsgrad’, ‘params’, ‘lr’, ‘betas’, ‘weight_decay’, ‘eps’]这6个参数
    """</span>
    <span class="hljs-keyword">for</span> param_group <span class="hljs-keyword">in</span> optimizer.param_groups:
        param_group[<span class="hljs-string">'lr0'</span>] = param_group[<span class="hljs-string">'lr'</span>]
    <span class="hljs-keyword">return</span> optimizer

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lr_scheduler</span><span class="hljs-params">(optimizer, iter_num, max_iter, gamma = <span class="hljs-number">10</span>, power = <span class="hljs-number">0.75</span>)</span>:</span>
    <span class="hljs-string">"""
    学习率衰减
    """</span>
    decay = (<span class="hljs-number">1</span> + gamma * iter_num / max_iter) ** (-power)
    <span class="hljs-keyword">for</span> param_group <span class="hljs-keyword">in</span> optimizer.param_groups:
        param_group[<span class="hljs-string">'lr'</span>] = param_group[<span class="hljs-string">'lr0'</span>] * decay
        param_group[<span class="hljs-string">'weight_decay'</span>] = <span class="hljs-number">1e-3</span>
        param_group[<span class="hljs-string">'momentum'</span>] = <span class="hljs-number">0.9</span>
        param_group[<span class="hljs-string">'nesterov'</span>] = <span class="hljs-literal">True</span>
    <span class="hljs-keyword">return</span> optimizer

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">digit_load</span><span class="hljs-params">(args)</span>:</span>
    <span class="hljs-string">"""
    加载数据集
    """</span>
    train_bs = args.batch_size
    
    <span class="hljs-keyword">if</span> args.dset == <span class="hljs-string">'s2m'</span>:
    <span class="hljs-string">"""
    SVHN-&gt;MNIST
    """</span>
        train_source = svhn.SVHN(<span class="hljs-string">'./data/svhn/'</span>, split = <span class="hljs-string">'train'</span>, download = <span class="hljs-literal">True</span>, 
            transform = transforms.Compose([
                transforms.Resize(<span class="hljs-number">32</span>),
                transforms.ToTensor(),
                transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))
            ])
            )
        test_source = svhn.SVHN(<span class="hljs-string">'./data/svhn/'</span>, split = <span class="hljs-string">'test'</span>, download = <span class="hljs-literal">True</span>,
            transform = transforms.Compose([
                transforms.Resize(<span class="hljs-number">32</span>),
                transforms.ToTensor(),
                transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))
            ])                   
            )
        train_target = mnist.MNIST_idx(<span class="hljs-string">'./data/mnist/'</span>, train = <span class="hljs-literal">True</span>, download = <span class="hljs-literal">True</span>,
            transform = transforms.Compose([
                transforms.Resize(<span class="hljs-number">32</span>),
                transforms.Lambda(<span class="hljs-keyword">lambda</span> x: x.convert(<span class="hljs-string">"RGB"</span>)),
                transforms.ToTensor(),
                transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))
            ])        
            )
        test_target = mnist.MNIST(<span class="hljs-string">'./data/mnist/'</span>, train = <span class="hljs-literal">False</span>, download = <span class="hljs-literal">True</span>,
            transform = transforms.Compose([
                transforms.Resize(<span class="hljs-number">32</span>),
                transforms.Lambda(<span class="hljs-keyword">lambda</span> x: x.convert(<span class="hljs-string">"RGB"</span>)),
                transforms.ToTensor(),
                transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))
            ])                     
            )
    <span class="hljs-keyword">elif</span> args.dset == <span class="hljs-string">'u2m'</span>:
    <span class="hljs-string">"""
    USPS-&gt;MNIST
    """</span>    
        train_source = usps.USPS(<span class="hljs-string">'./data/usps/'</span>, train = <span class="hljs-literal">True</span>, download = <span class="hljs-literal">True</span>,
            transform = transforms.Compose([
                transforms.RandomCrop(<span class="hljs-number">28</span>, padding = <span class="hljs-number">4</span>),
                transforms.RandomRotation(<span class="hljs-number">10</span>),
                transforms.ToTensor(),
                transforms.Normalize((<span class="hljs-number">0.5</span>, ), (<span class="hljs-number">0.5</span>, ))
            ])
            )
        test_source = usps.USPS(<span class="hljs-string">'./data/usps/'</span>, train = <span class="hljs-literal">False</span>, download = <span class="hljs-literal">True</span>,
            transform = transforms.Compose([
                transforms.RandomCrop(<span class="hljs-number">28</span>, padding = <span class="hljs-number">4</span>),
                transforms.RandomRotation(<span class="hljs-number">10</span>),
                transforms.ToTensor(),
                transforms.Normalize((<span class="hljs-number">0.5</span>, ), (<span class="hljs-number">0.5</span>, ))
            ])                    
            )
        train_target = mnist.MNIST_idx(<span class="hljs-string">'./data/mnist'</span>, train = <span class="hljs-literal">True</span>, download = <span class="hljs-literal">True</span>,
            transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize((<span class="hljs-number">0.5</span>, ), (<span class="hljs-number">0.5</span>, ))
            ])        
            )
        test_target = mnist.MNIST(<span class="hljs-string">'./data/mnist/'</span>, train = <span class="hljs-literal">False</span>, download = <span class="hljs-literal">True</span>,
            transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize((<span class="hljs-number">0.5</span>, ), (<span class="hljs-number">0.5</span>, ))
            ])                     
            )
        
    <span class="hljs-keyword">elif</span> args.dset = <span class="hljs-string">'m2u'</span>:
    <span class="hljs-string">"""
    MNIST-&gt;USPS
    """</span>train_source = mnist.MNIST(<span class="hljs-string">'./data/mnist/'</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>,
                transform=transforms.Compose([
                    transforms.ToTensor(),
                    transforms.Normalize((<span class="hljs-number">0.5</span>,), (<span class="hljs-number">0.5</span>,))
                ])
                )
        test_source = mnist.MNIST(<span class="hljs-string">'./data/mnist/'</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>,
                transform=transforms.Compose([
                    transforms.ToTensor(),
                    transforms.Normalize((<span class="hljs-number">0.5</span>,), (<span class="hljs-number">0.5</span>,))
                ])
                )
        train_target = usps.USPS_idx(<span class="hljs-string">'./data/usps/'</span>, train=<span class="hljs-literal">True</span>, download=<span class="hljs-literal">True</span>,
                transform=transforms.Compose([
                    transforms.ToTensor(),
                    transforms.Normalize((<span class="hljs-number">0.5</span>,), (<span class="hljs-number">0.5</span>,))
                ])
                )
        test_target = usps.USPS(<span class="hljs-string">'./data/usps/'</span>, train=<span class="hljs-literal">False</span>, download=<span class="hljs-literal">True</span>,
                transform=transforms.Compose([
                    transforms.ToTensor(),
                    transforms.Normalize((<span class="hljs-number">0.5</span>,), (<span class="hljs-number">0.5</span>,))
                ])
                )
        
    dset_loaders = {}
    <span class="hljs-string">"""
    DataLoader()对数据集进行批处理
    参数：
    dataset：Dataset类型，从其中加载数据 
    batch_size：int，可选。每个batch加载多少样本 
    shuffle：bool，可选。为True时表示每个epoch都对数据进行洗牌 
    sampler：Sampler，可选。从数据集中采样样本的方法。 
    num_workers：int，可选。加载数据时使用多少子进程。默认值为0，表示在主进程中加载数据。 
    collate_fn：callable，可选。 
    pin_memory：bool，可选 
    drop_last：bool，可选。True表示如果最后剩下不完全的batch,丢弃。False表示不丢弃。
    """</span>
    dset_loaders[<span class="hljs-string">"source_tr"</span>] = DataLoader(train_source, batch_size = train_bs, shuffle = <span class="hljs-literal">True</span>, num_workers = args.worker, drop_last = <span class="hljs-literal">False</span>)
    dset_loaders[<span class="hljs-string">"source_te"</span>] = DataLoader(test_source, batch_size = train_bs * <span class="hljs-number">2</span>, shuffle = <span class="hljs-literal">True</span>, num_workers = args.worker, drop_last = <span class="hljs-literal">False</span>)
    dset_loaders[<span class="hljs-string">"target"</span>] = DataLoader(train_target, batch_size = train_bs, shuffle = <span class="hljs-literal">True</span>, num_workers = args.worker, drop_last = <span class="hljs-literal">False</span>)
    dset_loaders[<span class="hljs-string">"target_te"</span>] = DataLoader(train_target, batch_size = train_bs, shuffle = <span class="hljs-literal">False</span>, num_workers = args.worker, drop_last = <span class="hljs-literal">False</span>)
    dset_loaders[<span class="hljs-string">"test"</span>] = DataLoader(test_target, batch_size = train_bs * <span class="hljs-number">2</span>, shuffle = <span class="hljs-literal">False</span>, num_workers = args.worker, drop_last =<span class="hljs-literal">False</span>)
    
    <span class="hljs-keyword">return</span> data_loaders
    
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cal_acc</span><span class="hljs-params">(loader, netF, netB, netC)</span>:</span>
    <span class="hljs-string">"""
    准确率计算
    """</span>
    start_test = <span class="hljs-literal">True</span>
    <span class="hljs-keyword">with</span> torch.no_grad():
    <span class="hljs-string">"""
    当我们在做 evaluating 的时候（不需要计算导数），我们可以将推断（inference）的代码包裹在 with torch.no_grad(): 之中，
    以达到暂时不追踪网络参数中的导数的目的，总之是为了减少可能存在的计算和内存消耗。
    """</span>
        iter_test = iter(loader)
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(loader)):
            data = iter_test.next()
            inputs = data[<span class="hljs-number">0</span>]
            labels = data[<span class="hljs-number">1</span>]
            inputs = inputs.cuda()
            outputs = netC(netB(netF(inputs)))
            <span class="hljs-keyword">if</span> start_test:
                all_output = outputs.float().cpu()
                all_label = labels.float()
                start_test = <span class="hljs-literal">False</span>
            <span class="hljs-keyword">else</span>:
                all_output = torch.cat((all_output, outputs.float().cpu()), <span class="hljs-number">0</span>)
                all_label = torch.cat((all_label, labels.float()), <span class="hljs-number">0</span>)
    _, predict = torch.max(all_output, <span class="hljs-number">1</span>)
    accuracy = torch.sum(torch.squeeze(predict).float() == all_label).item() / float(all_label.size()[<span class="hljs-number">0</span>])
    mean_ent = torch.mean(loss.Entropy(nn.Softmax(dim = <span class="hljs-number">1</span>)(all_output))).cpu().data.item()
    <span class="hljs-keyword">return</span> accuracy * <span class="hljs-number">100</span>, mean_ent

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_source</span><span class="hljs-params">(args)</span>:</span>
    <span class="hljs-string">"""
    训练源模型
    """</span>
    dset_loaders = digit_load(args)
    <span class="hljs-string">"""
    设置基本网络
    """</span>
    <span class="hljs-keyword">if</span> args.dset == <span class="hljs-string">'u2m'</span>:
        netF = network.LeNetBase().cuda()
    <span class="hljs-keyword">elif</span> args.dset == <span class="hljs-string">'m2u'</span>:
        netF = network.LeNetBase().cuda()
    <span class="hljs-keyword">elif</span> args.dset == <span class="hljs-string">'s2m'</span>:
        netF = network.DTNBase().cuda()
        
    netB = network.feat_bottleneck(type = args.classifier, feature_dim = netF.in_features, bottleneck_dim = args.bottleneck).cuda()
    netC = network.feat_classifier(type = args.layer, class_num = args.class_num, bottleneck_dim = args.bottleneck).cuda()
    
    <span class="hljs-string">"""
    优化器参数
    """</span>
    param_group = []
    learning_rate = args.lr
    <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> netF,named_parameters():
        param_group += [{<span class="hljs-string">'params'</span>:v, <span class="hljs-string">'lr'</span>:learning_rate}]
    <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> netB.named_parameters():
        param_group += [{<span class="hljs-string">'params'</span>:v, <span class="hljs-string">'lr'</span>:learning_rate}]
    <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> netC.named_parameters():
        param_group += [{<span class="hljs-string">'params'</span>:v, <span class="hljs-string">'lr'</span>:learning_rate}]
        
    optimizer = optim.SGD(param_group)
    optimizer = op_copy(optimizer)
    
    <span class="hljs-string">"""
    参数初始化
    """</span>
    acc_init = <span class="hljs-number">0</span> <span class="hljs-comment">#初始准确率</span>
    max_iter = args.max_epoch * len(dset_loaders[<span class="hljs-string">"source_tr"</span>]) <span class="hljs-comment">#最大迭代次数</span>
    interval_iter = max_iter // <span class="hljs-number">10</span> 
    iter_num = <span class="hljs-number">0</span>
    
    <span class="hljs-string">"""
    训练之前调整至train模式
    """</span>
    netF.train()
    netB.train()
    netC.train()
    
    <span class="hljs-string">"""
    开始循环迭代训练
    """</span>
    <span class="hljs-keyword">while</span> iter_num &lt; max_iter:
        <span class="hljs-keyword">try</span>:
            input_source, labels_source = iter_source.next()
        <span class="hljs-keyword">except</span>:
            iter_source = iter(dset_loaders[<span class="hljs-string">"source_tr"</span>])
            input_source, labels_source = iter_source.next()
            
        <span class="hljs-keyword">if</span> inputs_source.size(<span class="hljs-number">0</span>) == <span class="hljs-number">1</span>:
            <span class="hljs-keyword">continue</span>
            
        iter_num += <span class="hljs-number">1</span>
        lr_scheduler(optimizer, iter_num = iter_num, max_iter = max_iter)
        
        inputs_source, labels_source = inputs_source.cuda(), labels_source.cuda()
        outputs_source = netC(netB(netF(inputs_source)))
        classifier_loss = loss.CrossEntropyLabelSmooth(num_classes = arg.class_num, epsilon = args.smooth)(outputs_source, labels_source)
        optimizer.zero_grad()
        classifier_loss.backward()
        optimizer.step()
        
        <span class="hljs-keyword">if</span> iter_num % interval_iter == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> iter_num == max_iter:
            netF.eval()
            netB.eval()
            netC.eval()
            acc_s_tr, _ = cal_acc(dset_loaders[<span class="hljs-string">'source_tr'</span>], netF, netB, netC)
            acc_s_te, _ = cal_acc(dset_loaders[<span class="hljs-string">'source_te'</span>], netF, netB, netC)
            log_str = <span class="hljs-string">'Task: {},Iter: {} / {};Accuracy = {:.2f}%/{:.2f}%'</span>.format(args.dset, iter_num, max_iter, acc_s_tr, acc_s_te)
            args.out_file.write(log_str + <span class="hljs-string">'\n'</span>)
            args.out_file.flush()
            print(log_str + <span class="hljs-string">'\n'</span>)
            
            <span class="hljs-keyword">if</span> acc_s_te &gt;= acc_init:
                acc_init = acc_s_te
                best_netF = netF.state_dict()
                best_netB = netB.state_dict()
                best_netC = netC.state_dict()
            
    torch.save(best_netF, osp.join(args.output_dir, <span class="hljs-string">"source_F.pt"</span>))
    torch.save(best_netB, osp.join(args.output_dir, <span class="hljs-string">"source_B.pt"</span>))
    torch.save(best_netC, osp.join(args.output_dir, <span class="hljs-string">"source_C.pt"</span>))
    
    <span class="hljs-keyword">return</span> netF, netB, netC

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_target</span><span class="hljs-params">(args)</span>:</span>
    <span class="hljs-string">"""
    测试
    """</span>
    
    <span class="hljs-string">"""
    基本网络选择 netF，netB，netC
    """</span>
    dset_loaders = digit_load(args)
    <span class="hljs-keyword">if</span> args.dset == <span class="hljs-string">'u2m'</span>:
        netF = network.LeNetBase().cuda()
    <span class="hljs-keyword">elif</span> args.dset == <span class="hljs-string">'m2u'</span>:
        netF = network.LeNetBase().cuda()
    <span class="hljs-keyword">elif</span> args.dset == <span class="hljs-string">'s2m'</span>:
        netF = network.DTNBase().cuda()
        
    netB = network.feat_bottleneck(type = args.classifier, feature_dim = netF.in_features, bottleneck_dim = args.bottleneck).cuda()
    netC = network.feat_classifier(type = args.layer, class_num = args.class_num, bottleneck_dim = args.bottleneck).cuda()
    
    <span class="hljs-string">"""
    模型保存
    """</span>
    args.modelpath = args.output_dir + <span class="hljs-string">'/source_F.pt'</span>
    netF.load_state_dict(torch.load(args.modelpath))
    args.modelpath = args.output_dir + <span class="hljs-string">'/source_B.pt'</span>
    netB.load_state_dict(torch.load(args.modelpath))
    args.modelpath = args.output_dir + <span class="hljs-string">'/source_C.pt'</span>
    netC.load_state_dict(torch.load(args.modelpath))
    
    
    netF.eval()
    netB.eval()
    netC.eval()
    
    acc, _ = cal_acc(dset_loaders[<span class="hljs-string">'test'</span>], netF, netB, netC)
    log_str = <span class="hljs-string">'Task: {}, Accuracy = {:.2f}'</span>.format(args.dset, acc)
    args.out_file.write(log_str + <span class="hljs-string">'\n'</span>)
    args.out_file.flush()
    print(log_str + <span class="hljs-string">'\n'</span>)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">print_args</span><span class="hljs-params">(args)</span>:</span>
    s = <span class="hljs-string">"=====================\n"</span>
    <span class="hljs-keyword">for</span> arg, content <span class="hljs-keyword">in</span> args.__dict__.items():
        s += <span class="hljs-string">"{} : {}"</span>.format(arg, content)
    <span class="hljs-keyword">return</span> s

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_target</span><span class="hljs-params">(args)</span>:</span>
    <span class="hljs-string">"""
    目标域上训练模型
    """</span>
    
    <span class="hljs-string">"""
    对应模型加载
    """</span>
    dset_loaders = digit_load(args)
    <span class="hljs-keyword">if</span> args.dset == <span class="hljs-string">'u2m'</span>:
        netF = network.LeNetBase().cuda()
    <span class="hljs-keyword">elif</span> args.dset == <span class="hljs-string">'m2u'</span>:
        netF = network.LeNetBase().cuda()
    <span class="hljs-keyword">elif</span> args.dset == <span class="hljs-string">'s2m'</span>:
        netF = network.DTNBase().cuda()
        
    netB = network.feat_bottleneck(type = args.classifer, feature_dim = netF.in_features, bottleneck_dim = args.bottleneck).cuda()
    netC = network.feat_classifier(type = args.layer, class_num = args.class_num, bottleneck_dim = args.bottleneck).cuda()
    
    args.modelpath = args.output_dir + <span class="hljs-string">'/source_F.pt'</span>
    netF.load_state_dict(torch.load(args.modelpath))
    args.modelpath = args.output_dir + <span class="hljs-string">'/source_B.pt'</span>
    netB.load_state_dict(torch.load(args.modelpath))
    args.modelpath = args.output_dir + <span class="hljs-string">'/source_C.pt'</span>
    netC.load_state_dict(torch.load(args.modelpath))
    
    netC.eval()
    
    <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> netC.named_parameters():
        v.requires_grad = <span class="hljs-literal">False</span>
        
    param_group = []
    <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> netF.named_parameters():
        param_group += [{<span class="hljs-string">'params:'</span>v, <span class="hljs-string">'lr:'</span>args.lr}]
    <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> netB.named_parameters():
        param_group += [{<span class="hljs-string">'params:'</span>v, <span class="hljs-string">'lr:'</span>args.lr}]
    
    optimizer = optim.SGD(param_group)
    optimizer = op_copy(optimizer)
    
    max_iter = args.max_epoch * len(dset_loaders[<span class="hljs-string">"target"</span>])
    interval_iter = len(dset_loaders[<span class="hljs-string">"target"</span>])
    iter_num = <span class="hljs-number">0</span>
    
    <span class="hljs-string">"""
    开始迭代
    """</span>
    <span class="hljs-keyword">while</span> iter_num &lt; max_iter:
        optimizer.zero_grad()
        <span class="hljs-keyword">try</span>:
            inputs_test, tar_idx = iter_test.next()
        <span class="hljs-keyword">except</span>:
            iter_test = iter(dset_loaders[<span class="hljs-string">"target"</span>])
            inputs_test, _, tar_idx = iter_test.next()
            
        <span class="hljs-keyword">if</span> inputs_test.size(<span class="hljs-number">0</span>) == <span class="hljs-number">-1</span>:
            <span class="hljs-keyword">continue</span>
            
        <span class="hljs-keyword">if</span> iter_num % interval_iter == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> args.cls_par &gt; <span class="hljs-number">0</span>:
            netF.eval()
            netF.eval()
            mem_label = obtain_label(dset_loaders[<span class="hljs-string">'target_te'</span>], netF, netB, netC, args)
            mem_label = torch.from_numpy(mem_label).cuda()
            netF.train()
            netB.train()
            
        iter_num += <span class="hljs-number">1</span>
        lr_scheduler(optimizer, iter_num = iter_num, max_iter = max_iter)
        
        inputs_test = inputs_test.cuda()
        feature_test = netB(netF(inputs_test))
        outputs_test = netC(features_test)
        
        <span class="hljs-keyword">if</span> args.cls_par &gt; <span class="hljs-number">0</span>:
            pred = mean_label[tar_idx]
            classifier_loss = args.cls_par * nn.CrossEntropyLoss()(outputs_test, pred)
        <span class="hljs-keyword">else</span>:
            clssifier_loss = torch.tensor(<span class="hljs-number">0.0</span>).cuda()
            
        <span class="hljs-keyword">if</span> args.ent:
            softmax_out = nn.Softmax(dim = <span class="hljs-number">1</span>)(outputs_test)
            entropy_loss = torch.mean(loss.Entropy(softmax_out))
            <span class="hljs-keyword">if</span> args.gent:
                msoftmax = softmax_out.mean(dim = <span class="hljs-number">0</span>)
                entropy_loss -= torch.sum(-msoftmax * torch.log(msoftmax + <span class="hljs-number">1e-5</span>))
            im_loss = entropy_loss * args.ent_par
            classifier_loss += im_loss
        
        optimizer.zero_grad()
        classifier_loss.backward()
        optimizer.step()
        
        <span class="hljs-keyword">if</span> iter_num % interval_iter == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> iter_num == max_iter:
            netF.eval()
            netB.eval()
            acc,_ = cal_acc(dset_loaders[<span class="hljs-string">'test'</span>], netF, netB, netC)
            log_str = <span class="hljs-string">'Task:{}, Iter:{} / {};Accuracy = {:.2f}%'</span>.format(args.dset, iter_num, max_iter, acc)
            args.out_file.write(log_str + <span class="hljs-string">'\n'</span>)
            args.out_file.flush()
            print(log_str + <span class="hljs-string">'\n'</span>)
    <span class="hljs-string">"""
    保存模型
    """</span> 
    <span class="hljs-keyword">if</span> args.issave:
        torch.save(netF.state_dict(), osp.join(args.output_dir, <span class="hljs-string">"target_F_"</span> + args.savename + <span class="hljs-string">".pt"</span>))
        torch.save(netB.state_dict(), osp.join(args.output_dir, <span class="hljs-string">"target_B_"</span> + args.savename + <span class="hljs-string">".pt"</span>))
        torch.save(netC.state_dict(), osp.join(args.output_dir, <span class="hljs-string">"target_C_"</span> + args.savename + <span class="hljs-string">".pt"</span>))
    
    <span class="hljs-keyword">return</span> netF, netB, netC

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">obtain_label</span><span class="hljs-params">(loader, netF, netB, netC, args, c = None)</span>:</span>
    <span class="hljs-string">"""
    伪标签：标签获取
    """</span>
    start_test = <span class="hljs-literal">True</span>
    <span class="hljs-keyword">with</span> torch.no_grad():
        iter_test = iter(loader)
        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(len(loader)):
            data = iter_test.next()
            inputs = data[<span class="hljs-number">0</span>]
            labels = data[<span class="hljs-number">1</span>]
            inputs = inputs.cuda()
            feas = netB(netF(inputs))
            outputs = netC(feas)
            <span class="hljs-keyword">if</span> start_test:
                all_fea = feas.float().cpu()
                all_output = outputs.float().cpu()
                all_label = labels.float()
                start_test = <span class="hljs-literal">False</span>
            <span class="hljs-keyword">else</span>:
                all_fea = torch.cat((all_fea, feas.float().cpu()), <span class="hljs-number">0</span>)
                all_output = torch.cat((all_output, outputs.float().cpu()), <span class="hljs-number">0</span>)
                all_label = torch.cat((all_label, labels.float()), <span class="hljs-number">0</span>)
    all_output = nn.Softmax(dim = <span class="hljs-number">1</span>)(all_output)
    _,predict = torch.max(all_output, <span class="hljs-number">1</span>)
    accuracy = torch.sum(torch.squeeze(predict).float() == all_label).item() / float(all_label.size()[<span class="hljs-number">0</span>])
    
    all_fea = torch.cat((all_fea, torch.ones(all_fea.size(<span class="hljs-number">0</span>), <span class="hljs-number">1</span>)), <span class="hljs-number">1</span>)
    all_fea = (all_fea.t() / torch.norm(all_fea, p = <span class="hljs-number">2</span>, dim = <span class="hljs-number">1</span>)).t()
    all_fea = all_fea.float().cpu().numpy()
    
    K = all_output.size()
    aff = all_output.float().cpu().numpy()
    initc = aff.transpose().dot(all_fea)
    initc = initc / (<span class="hljs-number">1e-8</span> + aff.sum(axis = <span class="hljs-number">0</span>)[:,<span class="hljs-literal">None</span>])
    dd = cdist(all_fea, initc, <span class="hljs-string">'cosine'</span>)
    pred_label = dd.argmin(axis = <span class="hljs-number">1</span>)
    acc = np.sum(pred_label == all_label.float().numpy()) / len(all_fea)
    
    <span class="hljs-keyword">for</span> round <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>):
        aff = np.eye(K)[pred_label]
        initc = add.transpose().dot(all_fea)
        initc = initc / (<span class="hljs-number">1e-8</span> + aff.sum(axis = <span class="hljs-number">0</span>)[:,<span class="hljs-literal">None</span>])
        dd = cdist(all_fea, initc, <span class="hljs-string">'cosine'</span>)
        pred_label = dd.argmin(axis = <span class="hljs-number">1</span>)
        acc = np.sum(pred_label == all_label.float().numpy()) / len(all_fea)
        
    log_dir = <span class="hljs-string">'Accuracy = {:.2f}% -&gt; {:.2f}%'</span>.format(accuracy * <span class="hljs-number">100</span>, acc * <span class="hljs-number">100</span>)
    args.out_file.write(log_str + <span class="hljs-string">'\n'</span>)
    args.out_file.flush()
    print(log_str + <span class="hljs-string">'\n'</span>)
    <span class="hljs-keyword">return</span> pred_label.astype(<span class="hljs-string">'int'</span>)

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:
    <span class="hljs-string">"""
    class argparse.ArgumentParser(prog=None, usage=None, description=None, epilog=None, parents=[], 
    formatter_class=argparse.HelpFormatter, prefix_chars='-', fromfile_prefix_chars=None, 
    argument_default=None, conflict_handler='error', add_help=True, allow_abbrev=True, exit_on_error=True
    )
    
    prog - 程序的名称（默认：sys.argv[0]）

    usage - 描述程序用途的字符串（默认值：从添加到解析器的参数生成）

    description - 在参数帮助文档之前显示的文本（默认值：无）

    epilog - 在参数帮助文档之后显示的文本（默认值：无）

    parents - 一个 ArgumentParser 对象的列表，它们的参数也应包含在内

    formatter_class - 用于自定义帮助文档输出格式的类

    prefix_chars - 可选参数的前缀字符集合（默认值：'-'）

    fromfile_prefix_chars - 当需要从文件中读取其他参数时，用于标识文件名的前缀字符集合（默认值：None）

    argument_default - 参数的全局默认值（默认值： None）

    conflict_handler - 解决冲突选项的策略（通常是不必要的）

    add_help - 为解析器添加一个 -h/--help 选项（默认值： True）

    allow_abbrev - 如果缩写是无歧义的，则允许缩写长选项 （默认值：True）

    exit_on_error - 决定当错误发生时是否让 ArgumentParser 附带错误信息退出。 (默认值: True)
    """</span>
    parser = argparse.ArgumentParser(description=<span class="hljs-string">'SHOT'</span>)
    parser.add_argument(<span class="hljs-string">'--gpu_id'</span>, type=str, nargs=<span class="hljs-string">'?'</span>, default=<span class="hljs-string">'0'</span>, help=<span class="hljs-string">"device id to run"</span>)
    parser.add_argument(<span class="hljs-string">'--s'</span>, type=int, default=<span class="hljs-number">0</span>, help=<span class="hljs-string">"source"</span>)
    parser.add_argument(<span class="hljs-string">'--t'</span>, type=int, default=<span class="hljs-number">1</span>, help=<span class="hljs-string">"target"</span>)
    parser.add_argument(<span class="hljs-string">'--max_epoch'</span>, type=int, default=<span class="hljs-number">30</span>, help=<span class="hljs-string">"maximum epoch"</span>)
    parser.add_argument(<span class="hljs-string">'--batch_size'</span>, type=int, default=<span class="hljs-number">64</span>, help=<span class="hljs-string">"batch_size"</span>)
    parser.add_argument(<span class="hljs-string">'--worker'</span>, type=int, default=<span class="hljs-number">4</span>, help=<span class="hljs-string">"number of workers"</span>)
    parser.add_argument(<span class="hljs-string">'--dset'</span>, type=str, default=<span class="hljs-string">'s2m'</span>, choices=[<span class="hljs-string">'u2m'</span>, <span class="hljs-string">'m2u'</span>,<span class="hljs-string">'s2m'</span>])
    parser.add_argument(<span class="hljs-string">'--lr'</span>, type=float, default=<span class="hljs-number">0.01</span>, help=<span class="hljs-string">"learning rate"</span>)
    parser.add_argument(<span class="hljs-string">'--seed'</span>, type=int, default=<span class="hljs-number">2020</span>, help=<span class="hljs-string">"random seed"</span>)
    parser.add_argument(<span class="hljs-string">'--cls_par'</span>, type=float, default=<span class="hljs-number">0.3</span>)
    parser.add_argument(<span class="hljs-string">'--ent_par'</span>, type=float, default=<span class="hljs-number">1.0</span>)
    parser.add_argument(<span class="hljs-string">'--gent'</span>, type=bool, default=<span class="hljs-literal">True</span>)
    parser.add_argument(<span class="hljs-string">'--ent'</span>, type=bool, default=<span class="hljs-literal">True</span>)
    parser.add_argument(<span class="hljs-string">'--bottleneck'</span>, type=int, default=<span class="hljs-number">256</span>)
    parser.add_argument(<span class="hljs-string">'--layer'</span>, type=str, default=<span class="hljs-string">"wn"</span>, choices=[<span class="hljs-string">"linear"</span>, <span class="hljs-string">"wn"</span>])
    parser.add_argument(<span class="hljs-string">'--classifier'</span>, type=str, default=<span class="hljs-string">"bn"</span>, choices=[<span class="hljs-string">"ori"</span>, <span class="hljs-string">"bn"</span>])
    parser.add_argument(<span class="hljs-string">'--smooth'</span>, type=float, default=<span class="hljs-number">0.1</span>)   
    parser.add_argument(<span class="hljs-string">'--output'</span>, type=str, default=<span class="hljs-string">''</span>)
    parser.add_argument(<span class="hljs-string">'--issave'</span>, type=bool, default=<span class="hljs-literal">True</span>)
    args = parser.parse_args()
    args.class_num = <span class="hljs-number">10</span>
    
    os.environ[<span class="hljs-string">"CUDA_VISIBLE_DEVICES"</span>] = args.gpu_id
    SEED = args.seed
    torch.manual_seed(SEED)
    torch.cuda.manual_seed(SEED)
    np.random.seed(SEED)
    random.seed(SEED)
    
    args.output_dir = osp.join(args.output, <span class="hljs-string">'seed'</span>, str(args.seed), args.dset)
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> osp.exists(args.output_dir):
        os.system(<span class="hljs-string">'mkdir -p'</span> + args.output_dir)
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> osp.exists(args.output_dir):
        os.mkdir(args.output_dir)
        
    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> osp.exists(osp.join(args.output_dir + <span class="hljs-string">'./source_F.pt'</span>)):
        args.out_file = open(osp.join(args.output_dir, <span class="hljs-string">'log_src.txt'</span>), <span class="hljs-string">'w'</span>)
        args.out_file.write(print_args(args) + <span class="hljs-string">'\n'</span>)
        args.out_file.flush()
        train_source(args)
        test_target(args)
        
    args.savename = <span class="hljs-string">'par_'</span> + atr(args.cls_par)
    args.out_file = open(osp.join(args.output_dir, <span class="hljs-string">'log_tar_'</span> + args.savename + <span class="hljs-string">'.txt'</span>), <span class="hljs-string">'w'</span>)
    args.out_file.write(print(args) + <span class="hljs-string">'\n'</span>)
    args.out_file.flush()
    train_target(args)
</code></pre>
<h4 id="1-mnist-usps-m2u-shot-cls_par-01"><a class="markdownIt-Anchor" href="#1-mnist-usps-m2u-shot-cls_par-01"></a> 1. MNIST -&gt; USPS (m2u) SHOT (cls_par = 0.1)</h4>
<p><strong>①实验命令</strong></p>
<pre class="highlight"><code class="">!python uda_digit.py --dset m2u --gpu_id 0 --output ckps_digits --cls_par 0.1
</code></pre>
<p><strong>②实验结果</strong></p>
<pre class="highlight"><code class="">Accuracy = 94.07% -&gt; 95.11%
Task: m2u, Iter:117/3510; Accuracy = 96.94%
Accuracy = 96.84% -&gt; 96.71%
Task: m2u, Iter:234/3510; Accuracy = 97.10%
Accuracy = 97.06% -&gt; 96.77%
Task: m2u, Iter:351/3510; Accuracy = 97.42%
Accuracy = 96.87% -&gt; 96.77%
Task: m2u, Iter:468/3510; Accuracy = 97.37%
Accuracy = 96.93% -&gt; 96.92%
Task: m2u, Iter:585/3510; Accuracy = 97.63%
Accuracy = 97.32% -&gt; 97.19%
Task: m2u, Iter:702/3510; Accuracy = 97.74%
Accuracy = 97.39% -&gt; 97.16%
Task: m2u, Iter:819/3510; Accuracy = 97.37%
Accuracy = 97.31% -&gt; 97.18%
Task: m2u, Iter:936/3510; Accuracy = 97.85%
Accuracy = 97.47% -&gt; 97.34%
Task: m2u, Iter:1053/3510; Accuracy = 97.80%
Accuracy = 97.43% -&gt; 97.41%
Task: m2u, Iter:1170/3510; Accuracy = 97.80%
Accuracy = 97.59% -&gt; 97.46%
Task: m2u, Iter:1287/3510; Accuracy = 97.90%
Accuracy = 97.47% -&gt; 97.46%
Task: m2u, Iter:1404/3510; Accuracy = 97.85%
Accuracy = 97.57% -&gt; 97.55%
Task: m2u, Iter:1521/3510; Accuracy = 97.96%
Accuracy = 97.58% -&gt; 97.53%
Task: m2u, Iter:1638/3510; Accuracy = 97.90%
Accuracy = 97.66% -&gt; 97.61%
Task: m2u, Iter:1755/3510; Accuracy = 97.80%
Accuracy = 97.49% -&gt; 97.53%
Task: m2u, Iter:1872/3510; Accuracy = 97.69%
Accuracy = 97.62% -&gt; 97.54%
Task: m2u, Iter:1989/3510; Accuracy = 97.90%
Accuracy = 97.58% -&gt; 97.58%
Task: m2u, Iter:2106/3510; Accuracy = 97.74%
Accuracy = 97.57% -&gt; 97.54%
Task: m2u, Iter:2223/3510; Accuracy = 97.85%
Accuracy = 97.61% -&gt; 97.58%
Task: m2u, Iter:2340/3510; Accuracy = 97.85%
Accuracy = 97.63% -&gt; 97.57%
Task: m2u, Iter:2457/3510; Accuracy = 97.96%
Accuracy = 97.58% -&gt; 97.61%
Task: m2u, Iter:2574/3510; Accuracy = 98.01%
Accuracy = 97.71% -&gt; 97.59%
Task: m2u, Iter:2691/3510; Accuracy = 97.85%
Accuracy = 97.71% -&gt; 97.66%
Task: m2u, Iter:2808/3510; Accuracy = 97.85%
Accuracy = 97.61% -&gt; 97.66%
Task: m2u, Iter:2925/3510; Accuracy = 97.90%
Accuracy = 97.69% -&gt; 97.67%
Task: m2u, Iter:3042/3510; Accuracy = 97.80%
Accuracy = 97.66% -&gt; 97.66%
Task: m2u, Iter:3159/3510; Accuracy = 97.96%
Accuracy = 97.67% -&gt; 97.63%
Task: m2u, Iter:3276/3510; Accuracy = 97.85%
Accuracy = 97.61% -&gt; 97.57%
Task: m2u, Iter:3393/3510; Accuracy = 97.96%
Accuracy = 97.74% -&gt; 97.65%
Task: m2u, Iter:3510/3510; Accuracy = 97.90%
</code></pre>
<h4 id="2-mnist-usps-m2u-shot-im-cls_par-00"><a class="markdownIt-Anchor" href="#2-mnist-usps-m2u-shot-im-cls_par-00"></a> 2. MNIST -&gt; USPS (m2u) SHOT-IM (cls_par = 0.0)</h4>
<p><strong>①实验命令</strong></p>
<pre class="highlight"><code class="">!python uda_digit.py --dset m2u --gpu_id 0 --output ckps_digits --cls_par 0.0
</code></pre>
<p><strong>②实验结果</strong></p>
<pre class="highlight"><code class="">Task: m2u, Iter:2814/28140; Accuracy = 98.65%/ 98.78%
Task: m2u, Iter:5628/28140; Accuracy = 99.31%/ 99.20%
Task: m2u, Iter:8442/28140; Accuracy = 99.49%/ 99.32%
Task: m2u, Iter:11256/28140; Accuracy = 99.56%/ 99.37%
Task: m2u, Iter:14070/28140; Accuracy = 99.59%/ 99.37%
Task: m2u, Iter:16884/28140; Accuracy = 99.61%/ 99.31%
Task: m2u, Iter:19698/28140; Accuracy = 99.64%/ 99.37%
Task: m2u, Iter:22512/28140; Accuracy = 99.67%/ 99.33%
Task: m2u, Iter:25326/28140; Accuracy = 99.67%/ 99.36%
Task: m2u, Iter:28140/28140; Accuracy = 99.69%/ 99.36%
Task: m2u, Accuracy = 88.55%
Task: m2u, Iter:117/3510; Accuracy = 97.47%
Task: m2u, Iter:234/3510; Accuracy = 96.56%
Task: m2u, Iter:351/3510; Accuracy = 94.84%
Task: m2u, Iter:468/3510; Accuracy = 93.28%
Task: m2u, Iter:585/3510; Accuracy = 96.24%
Task: m2u, Iter:702/3510; Accuracy = 96.29%
Task: m2u, Iter:819/3510; Accuracy = 95.11%
Task: m2u, Iter:936/3510; Accuracy = 95.70%
Task: m2u, Iter:1053/3510; Accuracy = 92.63%
Task: m2u, Iter:1170/3510; Accuracy = 95.22%
Task: m2u, Iter:1287/3510; Accuracy = 94.73%
Task: m2u, Iter:1404/3510; Accuracy = 92.04%
Task: m2u, Iter:1521/3510; Accuracy = 92.69%
Task: m2u, Iter:1638/3510; Accuracy = 93.66%
Task: m2u, Iter:1755/3510; Accuracy = 92.47%
Task: m2u, Iter:1872/3510; Accuracy = 93.82%
Task: m2u, Iter:1989/3510; Accuracy = 91.67%
Task: m2u, Iter:2106/3510; Accuracy = 92.42%
Task: m2u, Iter:2223/3510; Accuracy = 91.40%
Task: m2u, Iter:2340/3510; Accuracy = 91.77%
Task: m2u, Iter:2457/3510; Accuracy = 92.90%
Task: m2u, Iter:2574/3510; Accuracy = 92.69%
Task: m2u, Iter:2691/3510; Accuracy = 92.15%
Task: m2u, Iter:2808/3510; Accuracy = 93.44%
Task: m2u, Iter:2925/3510; Accuracy = 90.75%
Task: m2u, Iter:3042/3510; Accuracy = 92.37%
Task: m2u, Iter:3159/3510; Accuracy = 92.15%
Task: m2u, Iter:3276/3510; Accuracy = 91.40%
Task: m2u, Iter:3393/3510; Accuracy = 92.15%
Task: m2u, Iter:3510/3510; Accuracy = 92.15%
</code></pre>
<h3 id="实验2unsupervised-open-set-domain-adaptation-oda-on-the-office-home-dataset"><a class="markdownIt-Anchor" href="#实验2unsupervised-open-set-domain-adaptation-oda-on-the-office-home-dataset"></a> 实验2：Unsupervised Open-set Domain Adaptation (ODA) on the Office-Home dataset</h3>
<ul>
<li><strong>Train model on the source domain A (s = 0)</strong></li>
</ul>
<p><strong>①实验命令</strong></p>
<pre class="highlight"><code class="">python image_source.py --trte val --da oda --output ckps/source/ --gpu_id 0 --dset office-home --max_epoch 50 --s 0
</code></pre>
<p><strong>②实验结果</strong></p>
<pre class="highlight"><code class="">Task: A, Iter:75/750; Accuracy = 78.64%
Task: A, Iter:150/750; Accuracy = 78.64%
Task: A, Iter:225/750; Accuracy = 77.67%
Task: A, Iter:300/750; Accuracy = 77.67%
Task: A, Iter:375/750; Accuracy = 80.58%
Task: A, Iter:450/750; Accuracy = 77.67%
Task: A, Iter:525/750; Accuracy = 77.67%
Task: A, Iter:600/750; Accuracy = 77.67%
Task: A, Iter:675/750; Accuracy = 79.61%
Task: A, Iter:750/750; Accuracy = 79.61%
Training: val, Task: AC, Accuracy = 5.82% / 2.68% / 84.39%
Training: val, Task: AP, Accuracy = 7.95% / 5.10% / 79.13%
Training: val, Task: AR, Accuracy = 9.02% / 6.23% / 78.81%
</code></pre>
<ul>
<li><strong>Adaptation to other target domains C and P and R, respectively</strong></li>
</ul>
<p><strong>①实验命令</strong></p>
<pre class="highlight"><code class="">python image_target_oda.py --cls_par 0.3 --da oda --dset office-home --gpu_id 0 --s 0 --output_src ckps/source/ --output ckps/target/
</code></pre>
<p><strong>②实验结果</strong></p>
<pre class="highlight"><code class="">Task: AC, Iter:69/1035; Accuracy = 5.88% / 3.80% / 57.66%
Task: AC, Iter:138/1035; Accuracy = 6.03% / 4.33% / 48.70%
Task: AC, Iter:207/1035; Accuracy = 6.18% / 4.63% / 44.72%
Task: AC, Iter:276/1035; Accuracy = 6.12% / 4.74% / 40.41%
Task: AC, Iter:345/1035; Accuracy = 6.31% / 5.03% / 38.55%
Task: AC, Iter:414/1035; Accuracy = 6.28% / 5.06% / 36.65%
Task: AC, Iter:483/1035; Accuracy = 6.36% / 5.21% / 35.17%
Task: AC, Iter:552/1035; Accuracy = 6.36% / 5.25% / 34.28%
Task: AC, Iter:621/1035; Accuracy = 6.42% / 5.33% / 33.72%
Task: AC, Iter:690/1035; Accuracy = 6.38% / 5.33% / 32.57%
Task: AC, Iter:759/1035; Accuracy = 6.35% / 5.33% / 31.93%
Task: AC, Iter:828/1035; Accuracy = 6.31% / 5.33% / 30.86%
Task: AC, Iter:897/1035; Accuracy = 6.36% / 5.40% / 30.26%
Task: AC, Iter:966/1035; Accuracy = 6.45% / 5.54% / 29.22%
Task: AC, Iter:1035/1035; Accuracy = 6.43% / 5.54% / 28.55%

Task: AP, Iter:70/1050; Accuracy = 9.13% / 7.23% / 56.44%
Task: AP, Iter:140/1050; Accuracy = 8.90% / 7.37% / 47.17%
Task: AP, Iter:210/1050; Accuracy = 8.79% / 7.42% / 43.10%
Task: AP, Iter:280/1050; Accuracy = 9.06% / 7.85% / 39.30%
Task: AP, Iter:350/1050; Accuracy = 9.15% / 8.02% / 37.45%
Task: AP, Iter:420/1050; Accuracy = 9.05% / 7.99% / 35.38%
Task: AP, Iter:490/1050; Accuracy = 9.21% / 8.25% / 33.16%
Task: AP, Iter:560/1050; Accuracy = 9.26% / 8.38% / 31.27%
Task: AP, Iter:630/1050; Accuracy = 9.22% / 8.38% / 30.26%
Task: AP, Iter:700/1050; Accuracy = 9.20% / 8.38% / 29.58%
Task: AP, Iter:770/1050; Accuracy = 9.17% / 8.38% / 28.90%
Task: AP, Iter:840/1050; Accuracy = 9.15% / 8.38% / 28.37%
Task: AP, Iter:910/1050; Accuracy = 9.11% / 8.38% / 27.28%
Task: AP, Iter:980/1050; Accuracy = 9.08% / 8.38% / 26.49%
Task: AP, Iter:1050/1050; Accuracy = 9.05% / 8.38% / 25.85%

Task: AR, Iter:68/1020; Accuracy = 9.35% / 7.34% / 59.55%
Task: AR, Iter:136/1020; Accuracy = 9.17% / 7.43% / 52.82%
Task: AR, Iter:204/1020; Accuracy = 9.41% / 7.80% / 49.59%
Task: AR, Iter:272/1020; Accuracy = 9.34% / 7.85% / 46.51%
Task: AR, Iter:340/1020; Accuracy = 9.35% / 7.96% / 44.07%
Task: AR, Iter:408/1020; Accuracy = 9.39% / 8.05% / 42.73%
Task: AR, Iter:476/1020; Accuracy = 9.49% / 8.23% / 40.84%
Task: AR, Iter:544/1020; Accuracy = 9.48% / 8.28% / 39.58%
Task: AR, Iter:612/1020; Accuracy = 9.41% / 8.23% / 38.83%
Task: AR, Iter:680/1020; Accuracy = 9.46% / 8.32% / 37.93%
Task: AR, Iter:748/1020; Accuracy = 9.36% / 8.28% / 36.51%
Task: AR, Iter:816/1020; Accuracy = 9.34% / 8.28% / 36.08%
Task: AR, Iter:884/1020; Accuracy = 9.32% / 8.28% / 35.49%
Task: AR, Iter:952/1020; Accuracy = 9.35% / 8.32% / 35.13%
Task: AR, Iter:1020/1020; Accuracy = 9.33% / 8.32% / 34.62%
</code></pre>

            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="www.simonworld.cn" rel="external nofollow noreferrer">SimonShenm</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="www.simonworld.cn/posts/8853.html">www.simonworld.cn/posts/8853.html</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="www.simonworld.cn" target="_blank">SimonShenm</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Pytorch/">
                                    <span class="chip bg-color">Pytorch</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="facebook,google,qq,wechat" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/posts/28277.html">
                    <div class="card-image">
                        
                        <img src="https://s3.ax1x.com/2020/11/17/DVIbdK.png" class="responsive-img" alt="笔记:Universal Source-Free Domain Adaptation">
                        
                        <span class="card-title">笔记:Universal Source-Free Domain Adaptation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                              笔记:Universal Source-Free Domain Adaptation


0. Abstract
1. Introduction
2. Related Work
3. Proposed approach

3.1. Le
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-11-17
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E8%AE%BA%E6%96%87/" class="post-category">
                                    论文
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Domain-Adaptation/">
                        <span class="chip bg-color">Domain Adaptation</span>
                    </a>
                    
                    <a href="/tags/Universal/">
                        <span class="chip bg-color">Universal</span>
                    </a>
                    
                    <a href="/tags/Source-Free/">
                        <span class="chip bg-color">Source-Free</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/posts/15793.html">
                    <div class="card-image">
                        
                        <img src="https://s1.ax1x.com/2020/10/13/0hjrNQ.jpg" class="responsive-img" alt="机器学习7：贝叶斯分类器">
                        
                        <span class="card-title">机器学习7：贝叶斯分类器</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                             机器学习7：贝叶斯分类器
 7.1 贝叶斯决策论
 1. 条件风险
将一个有NNN种类别的标记Y={c1,c2,...,cN}\mathcal{Y}=\{c_1,c_2,...,c_N\}Y={c1​,c2​,...,cN​}，用λij\
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-11-15
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E8%A5%BF%E7%93%9C%E4%B9%A6/" class="post-category">
                                    西瓜书
                                </a>
                            
                            <a href="/categories/%E8%A5%BF%E7%93%9C%E4%B9%A6/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    机器学习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">机器学习</span>
                    </a>
                    
                    <a href="/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/">
                        <span class="chip bg-color">贝叶斯分类器</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: 沿溪行<br />'
            + '文章作者: SimonShenm<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + 'WoW有人复制我的博客文字，谢谢您的赏识，别做违法乱纪的事情哦。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h1, h2, h3, h4, h5'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4, h5').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
    });
</script>

    

</main>



    <footer class="page-footer bg-color">
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2019</span>
            &nbsp;博客由&nbsp;<a href="Simon_Shenm@outlook.com" target="_blank">Simon</a>&nbsp;维护
            <!-- <a href="www.simonworld.cn" target="_blank">SimonShenm</a> -->
            |&nbsp;技术由&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>&nbsp;支持
            |&nbsp;主题由&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>&nbsp;提供
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">54k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/simonshenm" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:Simon_Shenm@outlook.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=822145977" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 822145977" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







</div>
    </div>
</footer>

<div class="progress-bar"></div>

<script language = javascript >
    function siteTime() {
        window.setTimeout("siteTime()", 1000);
        var seconds = 1000;
        var minutes = seconds * 60;
        var hours = minutes * 60;
        var days = hours * 24;
        var years = days * 365;
        var today = new Date();
        var todayYear = today.getFullYear();
        var todayMonth = today.getMonth() + 1;
        var todayDate = today.getDate();
        var todayHour = today.getHours();
        var todayMinute = today.getMinutes();
        var todaySecond = today.getSeconds();
        //var t1 = Date.UTC(2018, 08, 11, 00, 00, 00); //北京时间2018-2-13 00:00:00 
        var t1 = Date.UTC(2020, 02, 02, 20, 20, 20);
        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond); 
        var diff = t2 - t1; var diffYears = Math.floor(diff / years); 
        var diffDays = Math.floor((diff / days) - diffYears * 365); 
        var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours); 
        var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) / minutes); 
        var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours - diffMinutes * minutes) / seconds); document.getElementById("sitetime").innerHTML = "本站已运行 " +diffYears+" 年 "+diffDays + " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒"; 
    } 
	siteTime(); 
</script>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->


    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    

    
    
    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
